{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results so far\n",
    "\n",
    "|Id|Pre-processing|Model|Generation|Validation result|Validation CDG|Test result|\n",
    "|--|--------------|-----|----------|-----------------|--------------|-----------|\n",
    "|01|Lowercase, remove br|Simple BART base|Beam 10, sequences 10|-|-|10.41|\n",
    "|03|Lowercase, remove br|BART-large, batchsize 8, warmup steps 500, weight_decay=0.01, max epochs 6, select lowest loss in 10% val.|Beam 10, sequences 10|1.198717|-|13.57|\n",
    "|04|Lowercase, remove br|BART-base, batchsize 32, warmup steps 500, weight_decay=0.01, max epochs 10, select lowest loss in 10% val.|Beam 10, sequences 10|0.883147|-|11.47|\n",
    "|05|Lowercase, remove br|BART-large, batchsize 8x4, warmup steps 500, weight_decay=0.01, max epochs 10, select lowest loss in 10% val in last 4 steps|Beam 10, sequences 10|1.118869|-|14.84|\n",
    "|06|Lowercase, remove br|BART-large, batchsize 8x4, warmup steps 500, weight_decay=0.01, max epochs 4, select lowest loss in 10% val in last 4 steps|Beam 10, sequences 10|1.032960|-|15.12|\n",
    "|07|Lowercase, remove br, remove height of model (WRONG PREPROCESSING)|BART-large, batchsize 8x4, warmup steps 500, weight_decay=0.01, max epochs 7, select lowest loss in 10% val in last 4 steps|Beam 10, sequences 10|1.075144|-|0.04|\n",
    "|08|Lowercase, remove br, remove height of model|BART-large, batchsize 8x4, warmup steps 500, weight_decay=0.01, max epochs 9, select lowest loss in 10% val in last 4 steps|Beam 10, sequences 10|1.108078|-|15.4|\n",
    "|09|Lowercase, remove br, remove height of model, add crawled data v2, remove duplicates|BART-large, batchsize 8x4, warmup steps 500, weight_decay=0.01, max epochs 7, select lowest loss in 10% val in last 4 steps|Beam 10, sequences 10|0.941261|-|16.72|\n",
    "|10|Lowercase, remove br, remove height of model, add crawled data v2, remove duplicates|BART-large, batchsize 8x4, warmup steps 500, weight_decay=0.01, max epochs 7, select lowest loss in 10% val in last 4 steps|Beam 20, sequences 20, keep 10 different|0.941261|-|12.09|\n",
    "|11|Lowercase, remove br, remove height of model, add crawled data v2, remove duplicates|BART-base, batchsize 32, warmup steps 500, weight_decay=0.01, max epochs 10, select highest CDG in 10% val in last 7 steps|Beam 20, sequences 20, top_k=50, top_p=0.95, keep 10 different|0.751276|36.305989|13.71|\n",
    "|--|CHANGED VALIDATION SET TO AVOID DUPLICATES|-|-|-|-|-|\n",
    "|12|Lowercase, remove br, remove height of model, add crawled data v2, remove duplicates|BART-base, batchsize 16x2, warmup steps 500, weight_decay=0.01, max epochs 20, select highest CDG in 10% val|Beam 20, sequences 20, top_k=50, top_p=0.95, keep 10 different|1.0292483568191528|32.05586210342057|13.36|\n",
    "|13|Lowercase, remove br, remove height of model, add crawled data v2, remove duplicates|BART-large, batchsize 4x4x2GPUs, warmup steps 500, weight_decay=0.01, max epochs 20, select highest CDG in 10% val|Beam 20, sequences 20, top_k=50, top_p=0.95, keep 10 different|1.371944546699524|27.659937997270013|10.82|\n",
    "|14|Use 09 model|Use 09 model|Use 09 model with verbatim copy of test data|0.941261|-|10.4|\n",
    "|--|CHANGED VALIDATION SET TO AVOID DUPLICATE NAMES|-|-|-|-|-|\n",
    "|15|Lowercase, remove br, remove height of model v2, add crawled data v2, remove duplicates|BART-large, batchsize 4x8, warmup steps 500, weight_decay=0.01, max epochs 20, select highest CDG in 10% groups val|Beam 20, sequences 20, top_k=50, top_p=0.95, keep 10 different|1.3031184673309326|19.804526571240693|12.0|\n",
    "|16|Lowercase, remove br, remove height of model v2, add crawled data v2, remove duplicates|BART-large, batchsize 4x8x2, warmup steps 500, weight_decay=0.01, max epochs 7, select highest CDG in 10% groups val|Beam 10, sequences 10, keep 10 different|1.1919293403625488|19.258711170493612|9.07|\n",
    "|21|Lowercase, remove br, remove height of model v2, add crawled data v2, remove duplicates|BART-large, batchsize 4x8x2, warmup steps 500, weight_decay=0.01, max epochs 7, select highest CDG in 10% groups val|Beam 30, sequences 30, keep 10 different|1.1919293403625488|19.258711170493612|**27.37**|\n",
    "|22|Lowercase, remove br, remove height of model v2, add crawled data v2, remove duplicates|BART-large, batchsize 4x8x2, warmup steps 500, weight_decay=0.01, max epochs 7, select highest CDG in 10% groups val|Beam 30, sequences 30, keep 10 different, top_k=50, top_p=0.95, length_penalty=0|1.1919293403625488|19.258711170493612|25.21|\n",
    "|23|Lowercase, remove br, remove height of model v2, add crawled data v2, remove duplicates|BART-base, batchsize 16x2, warmup steps 500, weight_decay=0.01, max epochs 20, select highest CDG in 10% groups val|Beam 30, sequences 30, keep 10 different|1.065309762954712|21.21939303068624|26.92|\n",
    "|24|SAME AS 21|SAME AS 21|Beam 30, sequences 30, keep 10 different. Ranker DistilBERT 1 epoch|1.1919293403625488|19.258711170493612|22.94|\n",
    "|25|21 AND 23|21 AND 23|21 AND 23. Ranker DistilBERT 1 epoch|-|-|21.0|\n",
    "|26|21 AND 23|21 AND 23|21 AND 23. Ranker DistilBERT best val acc in 10 epochs|-|-|21.82|\n",
    "|27|21 AND 23|21 AND 23|21 AND 23. Ranker DistilBERT trained with base model predictions, 20K steps|-|-|13.12|\n",
    "|29|21 AND 23|21 AND 23|21 AND 23. Majority ranker|-|-|29.03|\n",
    "|31|Lowercase, remove br, remove height of model v2, add crawled data v2, remove duplicates|Pegasus-large, batchsize 4x8, warmup steps 500, weight_decay=0.01, max epochs 20, select highest CDG in 10% groups val|Beam 30, sequences 30, keep 10 different|1.4194680452346802|19.53309428603432|**26.04**|\n",
    "|32|21 AND 23 AND 31|21 AND 23 AND 31|21 AND 23 AND 31. Majority ranker|-|-|**30.94**|\n",
    "|33|21 AND 23 AND 31|21 AND 23 AND 31|21 AND 23 AND 31. Proposals postprocessing v1. Majority ranker|-|-|27.74|\n",
    "|34|21 AND 23 AND 31|21 AND 23 AND 31|21 AND 23 AND 31. XGB 100 ranker|-|-|15.97|\n",
    "|35|Lowercase, remove br, remove height of model v2, add crawled data v2, remove duplicates|t5-small, batchsize 4x8, warmup steps 500, weight_decay=0.01, max epochs 10, select highest CDG in 10% groups val|Beam 30, sequences 30, keep 10 different|1.3318167924880981|15.304882960040631|21.58|\n",
    "|36|Lowercase, remove br, remove height of model v2, add crawled data v2, remove duplicates|t5-small, batchsize 4x8, warmup steps 500, weight_decay=0.01, max epochs 30, select highest CDG in 10% groups val|Beam 30, sequences 30, keep 10 different|1.1738414764404297|17.287563936145304|25.1|\n",
    "|37|21 AND 23 AND 31 AND 36|21 AND 23 AND 31 AND 36|21 AND 23 AND 31 AND 36. Majority ranker|-|-|**32.0**|\n",
    "|38|Lowercase, remove br, remove height of model v2, add crawled data v2, remove duplicates|t5-small, batchsize 4x8, warmup steps 500, weight_decay=0.01, max epochs 60, select highest CDG in 10% groups val|Beam 30, sequences 30, keep 10 different|1.1491024494171143|17.512197973119022|**25.83**|\n",
    "|39|21 AND 23 AND 31 AND 38|21 AND 23 AND 31 AND 38|21 AND 23 AND 31 AND 38. Majority ranker|-|-|31.89|\n",
    "|40|Lowercase, remove br, remove height of model v2, add crawled data v2, remove duplicates|t5-base, batchsize 8x8, warmup steps 500, weight_decay=0.01, max epochs 30, select highest CDG in 10% groups val|Beam 30, sequences 30, keep 10 different|1.0651754140853882|20.425836515899576|27.71|\n",
    "|41|40 AND 21 AND 23 AND 31 AND 36|40 AND 21 AND 23 AND 31 AND 36|40 AND 21 AND 23 AND 31 AND 36. Majority ranker|-|-|32.91|\n",
    "|42|21+40+23+38+30+36|21+40+23+38+30+36|Combinatorial ranker: 21->40->23->38->30|-|-|31.81|\n",
    "|43|21+40+23+38+30+36|21+40+23+38+30+36|XGBRanker negative subsample 1%, 50 iterations|-|-|12.16|\n",
    "|44|21+40+23+38+30+36|21+40+23+38+30+36|XGBRanker negative subsample 10%, 50 iterations|-|-|13.22|\n",
    "|45|40 AND 21 AND 23 AND 31 AND 36|40 AND 21 AND 23 AND 31 AND 36|40 AND 21 AND 23 AND 31 AND 36. Majority ranker with local deduplication|-|-|32.16|\n",
    "|46|Lowercase, remove br, remove height of model v2, add crawled data v2, remove duplicates|BART-base ensemble x4, batchsize 16x4, warmup steps 500, weight_decay=0.01, max epochs 20, select highest CDG in 10% groups val|Beam 30, sequences 30, keep 10 different. Majority ranker with local deduplication|-|-|25.3|\n",
    "|47|Lowercase, remove br, remove height of model v2, add crawled data v2, remove duplicates|BART-base ensemble x4, batchsize 16x4, warmup steps 500, weight_decay=0.01, max epochs 20, select highest CDG in 10% groups val|Beam 30, sequences 30, keep 10 different. Majority ranker|-|-|27.42|\n",
    "|48|Lowercase, remove br, remove height of model v2, add crawled data v2, remove duplicates|BART-base ensemble x21, batchsize 16x4, warmup steps 500, weight_decay=0.01, max epochs 20, select highest CDG in 10% groups val|Beam 30, sequences 30, keep 10 different. Majority ranker|-|-|29.38|\n",
    "|49|48->40->21->31->36|48->40->21->31->36|48->40->21->31->36. Majority ranker with local deduplication|-|-|32.72|\n",
    "|50|Lowercase, remove br, remove height of model v2, add crawled data v2, remove duplicates|t5-base ensemble x5, batchsize 8x8, warmup steps 500, weight_decay=0.01, max epochs 30, select highest CDG in 10% groups val|Beam 30, sequences 30, keep 10 different|-|-|29.07|\n",
    "|51|48->50->21->31->36|48->40->21->31->36|48->40->21->31->36. Majority ranker with local deduplication|-|-|32.97|\n",
    "|52|48->50->21->31->36|48->40->21->31->36|48->40->21->31->36. Majority ranker with global deduplication|-|-|9.43|\n",
    "|53|48->50->21->31->36|48->40->21->31->36|48->40->21->31->36. Majority ranker with no deduplication|-|-|33.71|\n",
    "|54|48->50->21->31->36|48->40->21->31->36|48->40->21->31->36. DCG ranker with no deduplication|-|-|32.57|\n",
    "|55|Lowercase, remove br, remove height of model v2, add crawled data v2, remove duplicates|t5-base ensemble x12, batchsize 8x8, warmup steps 500, weight_decay=0.01, max epochs 30, select highest CDG in 10% groups val|Beam 30, sequences 30, keep 10 different|-|-|**29.08**|\n",
    "|56|Lowercase, remove br, remove height of model v2, add crawled data v2, remove duplicates|BART-large ensemble x22, batchsize 4x16, warmup steps 500, weight_decay=0.01, max epochs 7, select highest CDG in 10% groups val|Beam 30, sequences 30, keep 10 different|||**30.29**|\n",
    "|57|56->48->55->31->36|56->48->55->31->36|56->48->55->31->36. DCG ranker with no deduplication|-|-|34.21|\n",
    "|58|Lowercase, remove br, remove height of model v2, add crawled data v2, remove duplicates|Pegasus-large ensemble x11, batchsize 2x32, warmup steps 500, weight_decay=0.01, max epochs 20, select highest CDG in 10% groups val|Beam 30, sequences 30, keep 10 different|||**29.79**|\n",
    "|59|56->58->48->55->36|56->58->48->55->36|56->58->48->55->36. DCG ranker with no deduplication|-|-|34.29|\n",
    "|60|Lowercase, remove br, remove height of model v2, add crawled data v2, remove duplicates|t5-small ensemble x12, batchsize 8x8, warmup steps 500, weight_decay=0.01, max epochs 60, select highest CDG in 10% groups val|Beam 30, sequences 30, keep 10 different|||**26.68**|\n",
    "|61|56->58->48->55->60|56->58->48->55->60|56->58->48->55->60. DCG ranker with no deduplication|-|-|34.04|\n",
    "|62|56->58->48->55|56->58->48->55|56->58->48->55. DCG ranker with no deduplication|-|-|33.73|\n",
    "|63|Lowercase, remove br, remove height of model v2, add crawled data v2, remove duplicates|BART-large ensemble x22, batchsize 4x16, warmup steps 500, weight_decay=0.01, max epochs 7, select highest CDG in 10% groups val|Beam 30, sequences 30, keep 10 different. Sorted models by OOB|||29.83|\n",
    "|64|Lowercase, remove br, remove height of model v2, add crawled data v2, remove duplicates|BART-large ensemble x22, batchsize 4x16, warmup steps 500, weight_decay=0.01, max epochs 7, select highest CDG in 10% groups val|Beam 30, sequences 30, keep 10 different. Sorted model proposals by weighted OOB|||29.84|\n",
    "|65|48+55+56+58+60|48+55+56+58+60|48+55+56+58+60. Sorted all base models by OOB|-|-|34.77|\n",
    "|66|48+55+56+58+60|48+55+56+58+60|48+55+56+58+60. Sorted all base model proposals by weighted OOB|-|-|34.83|\n",
    "|67|48+55+56+58+60|48+55+56+58+60|48+55+56+58+60. Sorted all base model proposals by weighted OOB + model-locally DCG rank|-|-|31.37|\n",
    "|69|48+55+56+58+60|48+55+56+58+60|48+55+56+58+60. Sorted all base model proposals by weighted combination optimizing OOB with BayesSearch(100)|-|-|34.43|\n",
    "|70|Lowercase, remove br, remove height of model v2, add crawled data v3, remove duplicates|BART-base, batchsize 16x2, warmup steps 500, weight_decay=0.01, max epochs 20 (best at 6), select highest CDG in 10% groups val|Beam 30, sequences 30, keep 10 different|1.011124610900879|22.099436319990666|**28.16**|\n",
    "|71|Lowercase, remove br, remove height of model v2, add crawled data v3, remove duplicates|BART-large ensemble x14, batchsize 4x16, warmup steps 500, weight_decay=0.01, max epochs 7, select highest CDG in 10% groups val|Beam 30, sequences 30, keep 10 different|||30.1|\n",
    "|72|56->71->58->48->55->60|56->71->58->48->55->60|56->71->58->48->55->60. Majority ranker with no deduplication|-|-| 33.71|\n",
    "|73|48+55+56+58+60+71|48+55+56+58+60|48+55+56+58+60. Sorted all base model proposals by weighted OOB|-|-|**34.90**|\n",
    "|74|48+55+56+58+60+71|48+55+56+58+60|48+55+56+58+60. Sorted all base model proposals by weighted OOB + description copypasta crawled data v4|-|-|**35.37**|\n",
    "|76|48+55+56+58+60+71|48+55+56+58+60|48+55+56+58+60. Sorted all base model proposals by weighted OOB + description copypasta crawled data v5|-|-|37.12|\n",
    "|77|Lowercase, remove br, remove height of model v2, add crawled data v4, remove duplicates|BART-large ensemble x5, batchsize 4x16, warmup steps 500, weight_decay=0.01, max epochs 7, select highest CDG in 10% groups val|Beam 30, sequences 30, keep 10 different|||29.76|\n",
    "|78|48+55+56+58+60+71+77|48+55+56+58+60+77|48+55+56+58+60+77. Sorted all base model proposals by weighted OOB|-|-|34.79|\n",
    "|79|48+55+56+58+60+71+77|48+55+56+58+60+77|48+55+56+58+60+77. Sorted all base model proposals by weighted OOB + description copypasta crawled data v5|-|-|36.97|\n",
    "|80|Lowercase, remove br, remove height of model v2, add crawled data v5, remove duplicates|BART-large ensemble x2, batchsize 4x16, warmup steps 500, weight_decay=0.01, max epochs 7, select highest CDG in 10% groups val|Beam 30, sequences 30, keep 10 different|||28.62|\n",
    "|81|48+55+56+58+60+71+77+80|48+55+56+58+60+77+80|48+55+56+58+60+77+80. Sorted all base model proposals by weighted OOB|-|-|34.77|\n",
    "|82|48+55+56+58+60+71+77+80|48+55+56+58+60+77+80|48+55+56+58+60+77+80. Sorted all base model proposals by weighted OOB  + description copypasta crawled data v6|-|-|37.0|\n",
    "|83|48+55+56+58+60+71+77+80|48+55+56+58+60+77+80|48+55+56+58+60+77+80. Sorted all base model proposals by weighted OOB  + description copypasta crawled data v6 with estimated DCG score|-|-|34.82|\n",
    "|84|82->79->74->66->59->57 ->61->49->45->41->37->32|82->79->74->66->59->57 ->61->49->45->41->37->32|82->79->74->66->59->57 ->61->49->45->41->37->32|-|-|34.54|\n",
    "|85|48+55+56+58+60+71+77+80|48+55+56+58+60+77+80|48+55+56+58+60+77+80. Sorted all base model proposals by weighted OOB  + description copypasta crawled data v6 with estimated DCG score|-|-|34.97|\n",
    "|86|48+55+56+58+60+71+77+80|48+55+56+58+60+77+80|48+55+56+58+60+77+80. Sorted all base model proposals by weighted OOB  + description copypasta crawled data v6|-|-|37.14|\n",
    "|87|48+55+56+58+60+71+80|same|same. Sorted all base model proposals by weighted OOB + description copypasta crawled data v6|-|-|**37.2**|\n",
    "|88|48+55+56+58+60+71+80|same|same. Sorted all base model proposals by weighted OOB  * ensemble test score + description copypasta crawled data v6|-|-|37.16|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now training: BART-large ensemble with v6 crawl, validation split from original data\n",
    "\n",
    "## Leakage??\n",
    "\n",
    "Using crawls v4, it is possible to copy&paste the name for those products in train with identical description as those of the test data, and we get a small improvement in performance (about 0.5 points). If we use crawls v5 we get a significant improvement (about 2.2 points compared to not using this strategy).\n",
    "\n",
    "## Crawls\n",
    "\n",
    "* v1: first version from Zara web\n",
    "* v2: improved version from Zara web\n",
    "* v3: v2 + Zara Home\n",
    "* v4: v3 + new Spring crawl from Zara web\n",
    "* v5: v4 + Yahoo crawl + small international crawl\n",
    "* v6: v5 + another international crawl\n",
    "\n",
    "## Improvements\n",
    "\n",
    "* More summarization models to try: sshleifer/distilbart-cnn-12-6, t5-large, sshleifer/distill-pegasus-cnn-16-4,  sshleifer/distilbart-cnn-12-3\n",
    "    * t5-large is too large, we can train it only with batchsize 1 and run out of memory when generating names.\n",
    "* DistilBERT based classifier to compute similarity between proposed name and description.\n",
    "    * Doesn't seem to be learning anything useful. Maybe try with sentence-transformers?\n",
    "* char-n-gram based classifier to compute similarity between proposed name and description. Can be a HashingVectorizer of both texts + AND of features, followed by XGB.\n",
    "    * sklearn crashes when vectorizing whole dataset. Using a 10% of the data and n-gram intersection features we get poor results.\n",
    "* Fine-tune model parameters with Population Based Training.\n",
    "* Filter generated texts using a dictionary. Discard texts with out-of-dictionary words.\n",
    "\n",
    "## Ideas that didn't work\n",
    "\n",
    "* Resorting proposals in a BART-base model by their loglikelihood, both with length penalty and without it.\n",
    "* When ensembling, deduplicating repetitions of the same proposal from the same model. There seems to be some hidden knowledge there that is useful. Maybe the model arrives at the same text through different generation paths or word pieces?\n",
    "* Removing one of the components in the ensemble. Even if it produces bad results on isolation, it improves the ensemble performance.\n",
    "* Hyperhyperensembles: ensembles of several submissions, each one an ensemble of several ensembles of the same model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
